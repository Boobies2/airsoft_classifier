{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import os\n",
        "from collections import Counter\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "BZrvxHX3vs-B"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WzcIMcl9vp7s"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = '/content/drive/MyDrive/Terraria/dataset'\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = (224, 224)\n",
        "NUM_EPOCHS = 15\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_CLASSES = 11"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_NAMES = [\n",
        "    \"ak\", \"pistol\", \"rifle\", \"helmet\", \"pounch\",\n",
        "    \"shutgun\", \"vest\", \"M series\", \"mashinegun\", \"backpack\",\n",
        "    \"other\"\n",
        "]"
      ],
      "metadata": {
        "id": "pWKWgp34vujg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Msk-WTwHvwRb",
        "outputId": "b0fd5b66-2ba6-49df-9385-fe9bbe083385"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(IMAGE_SIZE),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(IMAGE_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "metadata": {
        "id": "veWLhdtEvyI4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.classes = CLASS_NAMES\n",
        "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
        "        self.samples = self._make_dataset()\n",
        "\n",
        "    def _make_dataset(self):\n",
        "        samples = []\n",
        "        for class_name in self.classes:\n",
        "            class_dir = os.path.join(self.root_dir, class_name)\n",
        "            if not os.path.isdir(class_dir):\n",
        "                continue\n",
        "            for filename in os.listdir(class_dir):\n",
        "                if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    path = os.path.join(class_dir, filename)\n",
        "                    item = (path, self.class_to_idx[class_name])\n",
        "                    samples.append(item)\n",
        "        return samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.samples[idx]\n",
        "        image = Image.open(path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "CQW-ckY4v2nk"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset = CustomDataset(root_dir=DATA_DIR, transform=data_transforms['train'])\n",
        "\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "val_dataset.dataset.transform = data_transforms['val']\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmKP39YDv_wd",
        "outputId": "fe4bd31a-a5a5-4e05-8670-4cb54727282a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "qk6UdOGnwIyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe3ce76-dd2f-4cc9-bbfe-f8b99e70b9d7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 167MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "OCwmne0dwKro"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=NUM_EPOCHS):\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "                dataloader = train_loader\n",
        "            else:\n",
        "                model.eval()\n",
        "                dataloader = val_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloader.dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "        print()\n",
        "\n",
        "    print(f'Best val Acc: {best_acc:.4f}')\n",
        "    return model"
      ],
      "metadata": {
        "id": "mZ6jzP5WwNA2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(model, criterion, optimizer, scheduler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjlqwGiMwP24",
        "outputId": "83c00ed6-f8d8-4f62-b7e1-f334e8b9e0ec"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.6862 Acc: 0.7936\n",
            "val Loss: 2.4867 Acc: 0.6288\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.2689 Acc: 0.9129\n",
            "val Loss: 0.6508 Acc: 0.8636\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.1358 Acc: 0.9583\n",
            "val Loss: 1.8496 Acc: 0.6894\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.0832 Acc: 0.9792\n",
            "val Loss: 0.2924 Acc: 0.9470\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.0506 Acc: 0.9811\n",
            "val Loss: 0.3502 Acc: 0.8864\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.0441 Acc: 0.9924\n",
            "val Loss: 0.3284 Acc: 0.9091\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.0905 Acc: 0.9754\n",
            "val Loss: 0.8993 Acc: 0.8106\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.0293 Acc: 0.9905\n",
            "val Loss: 0.3051 Acc: 0.9167\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.0085 Acc: 0.9981\n",
            "val Loss: 0.2210 Acc: 0.9394\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.0096 Acc: 1.0000\n",
            "val Loss: 0.2136 Acc: 0.9318\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.0050 Acc: 1.0000\n",
            "val Loss: 0.2103 Acc: 0.9394\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.0044 Acc: 1.0000\n",
            "val Loss: 0.2150 Acc: 0.9470\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.0028 Acc: 1.0000\n",
            "val Loss: 0.2125 Acc: 0.9470\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.0037 Acc: 1.0000\n",
            "val Loss: 0.2125 Acc: 0.9470\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.0030 Acc: 1.0000\n",
            "val Loss: 0.2210 Acc: 0.9470\n",
            "\n",
            "Best val Acc: 0.9470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def save_model(model, path='weapon_classifier.pth'):\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'class_names': CLASS_NAMES\n",
        "    }, path)\n",
        "    print(f\"Model saved to {path}\")\n"
      ],
      "metadata": {
        "id": "psIH6yAh2qED"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr3TjtKw2tzm",
        "outputId": "38616919-bc77-4dc7-e689-c37d06883cb8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to weapon_classifier.pth\n"
          ]
        }
      ]
    }
  ]
}